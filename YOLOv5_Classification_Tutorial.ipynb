{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vm-insights/topicmodelling/blob/master/YOLOv5_Classification_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5 Classification Tutorial\n",
        "\n",
        "YOLOv5 supports classification tasks too. This is the official YOLOv5 classification notebook tutorial. YOLOv5 is maintained by [Ultralytics](https://github.com/ultralytics/yolov5).\n",
        "\n",
        "This notebook covers:\n",
        "\n",
        "*   Inference with out-of-the-box YOLOv5 classification on ImageNet\n",
        "*  [Training YOLOv5 classification](https://blog.roboflow.com//train-YOLOv5-classification-custom-data) on custom data\n",
        "\n",
        "*Looking for custom data? Explore over 66M community datasets on [Roboflow Universe](https://universe.roboflow.com).*\n",
        "\n",
        "This notebook was created with Google Colab. [Click here](https://colab.research.google.com/drive/1FiSNz9f_nT8aFtDEU3iDAQKlPT8SCVni?usp=sharing) to run it."
      ],
      "metadata": {
        "id": "5GYQX3of4QiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Pull in respective libraries to prepare the notebook environment."
      ],
      "metadata": {
        "id": "-PJ8vlYXbWtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pIM7fOwm8A7l",
        "outputId": "5d8faf29-010b-4f78-c351-32cc5210c9ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 23.6/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Infer on ImageNet\n",
        "\n",
        "To demonstrate YOLOv5 classification, we'll leverage an already trained model. In this case, we'll download the ImageNet trained models pretrained on ImageNet using YOLOv5 Utils."
      ],
      "metadata": {
        "id": "i_DrUi2nmF40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/train_data.zip  -d /content/"
      ],
      "metadata": {
        "id": "vL0T3td5dmHF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.downloads import attempt_download\n",
        "\n",
        "p5 = ['n', 's', 'm', 'l', 'x']  # P5 models\n",
        "cls = [f'{x}-cls' for x in p5]  # classification models\n",
        "\n",
        "for x in cls:\n",
        "    attempt_download(f'weights/yolov5{x}.pt')"
      ],
      "metadata": {
        "id": "o2scLEh6EYnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can infer on an example image from the ImageNet dataset."
      ],
      "metadata": {
        "id": "Fn2_a38DmZ2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download example image\n",
        "import requests\n",
        "image_url = \"https://i.imgur.com/OczPfaz.jpg\"\n",
        "img_data = requests.get(image_url).content\n",
        "with open('bananas.jpg', 'wb') as handler:\n",
        "    handler.write(img_data)"
      ],
      "metadata": {
        "id": "L9objhVHnS-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Infer using classify/predict.py\n",
        "!python classify/predict.py --weights ./weigths/yolov5s-cls.pt --source bananas.jpg"
      ],
      "metadata": {
        "id": "qqxF5pHCrLd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output, we can see the ImageNet trained model correctly predicts the class `banana` with `0.95` confidence."
      ],
      "metadata": {
        "id": "yQmj7IXqo3kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. (Optional) Validate\n",
        "\n",
        "Use the `classify/val.py` script to run validation for the model. This will show us the model's performance on each class.\n",
        "\n",
        "First, we need to download ImageNet."
      ],
      "metadata": {
        "id": "5EosQzyDCk3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # WARNING: takes ~20 minutes\n",
        "# !bash data/scripts/get_imagenet.sh --val"
      ],
      "metadata": {
        "id": "HwAYptjCq-C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the validation script\n",
        "# !python classify/val.py --weights ./weigths/yolov5s-cls.pt --data ../datasets/imagenet"
      ],
      "metadata": {
        "id": "CoHdKXWc8hrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows accuracy metrics for the ImageNet validation dataset including per class accuracy."
      ],
      "metadata": {
        "id": "r2coOcIjuzCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train On Custom Data\n",
        "\n",
        "To train on custom data, we need to prepare a dataset with custom labels.\n",
        "\n",
        "To prepare custom data, we'll use [Roboflow](https://roboflow.com). Roboflow enables easy dataset prep with your team, including labeling, formatting into the right export format, deploying, and active learning with a `pip` package. \n",
        "\n",
        "If you need custom data, there are over 66M open source images from the community on [Roboflow Universe](https://universe.roboflow.com).\n",
        "\n",
        "(For more guidance, here's a detailed blog on [training YOLOv5 classification on custom data](https://blog.roboflow.com/train-YOLOv5-classification-custom-data).)\n",
        "\n",
        "\n",
        "Create a free Roboflow account, upload your data, and label. \n",
        "\n",
        "![](https://s4.gifyu.com/images/fruit-labeling.gif)"
      ],
      "metadata": {
        "id": "9bXHHYeVDCXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Custom Dataset\n",
        "\n",
        "Next, we'll export our dataset into the right directory structure for training YOLOv5 classification to load into this notebook. Select the `Export` button at the top of the version page, `Folder Structure` type, and `show download code`.\n",
        "\n",
        "The ensures all our directories are in the right format:\n",
        "\n",
        "```\n",
        "dataset\n",
        "‚îú‚îÄ‚îÄ train\n",
        "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ class-one\n",
        "‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ IMG_123.jpg\n",
        "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ class-two\n",
        "‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ IMG_456.jpg\n",
        "‚îú‚îÄ‚îÄ valid\n",
        "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ class-one\n",
        "‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ IMG_789.jpg\n",
        "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ class-two\n",
        "‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ IMG_101.jpg\n",
        "‚îú‚îÄ‚îÄ test\n",
        "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ class-one\n",
        "‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ IMG_121.jpg\n",
        "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ class-two\n",
        "‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ IMG_341.jpg\n",
        "```\n",
        "\n",
        "![](https://i.imgur.com/BF9BNR8.gif)\n",
        "\n",
        "\n",
        "Copy and paste that snippet into the cell below."
      ],
      "metadata": {
        "id": "Cu6-lrukD6Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we're in the right directory to download our custom dataset\n",
        "import os\n",
        "os.makedirs(\"../datasets/\", exist_ok=True)\n",
        "%cd ../datasets/"
      ],
      "metadata": {
        "id": "6IIgJbP7G6Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE the below with your exported code snippet from above\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR API KEY\")\n",
        "project = rf.workspace(\"yolov5-classification\").project(\"banana-ripeness-classification\")\n",
        "dataset = project.version(1).download(\"folder\")"
      ],
      "metadata": {
        "id": "He6JwHIlG-W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the dataset name to the environment so we can use it in a system call later\n",
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"DATASET_NAME\"] = dataset_name"
      ],
      "metadata": {
        "id": "wLQbThFICpn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train On Custom Data üéâ\n",
        "Here, we use the DATASET_NAME environment variable to pass our dataset to the `--data` parameter.\n",
        "\n",
        "Note: we're training for 100 epochs here. We're also starting training from the pretrained weights. Larger datasets will likely benefit from longer training. "
      ],
      "metadata": {
        "id": "-5z7Yv42FGrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "!python train.py --model yolov5s-cls.pt --data custom_data.yaml --epochs 3 --img 128 --pretrained weights/yolov5s-cls.pt"
      ],
      "metadata": {
        "id": "MXWTTN2BEaqe",
        "outputId": "73f1977d-f970-4f42-982b-5ec1d27fe078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "usage: train.py\n",
            "       [-h]\n",
            "       [--weights WEIGHTS]\n",
            "       [--cfg CFG]\n",
            "       [--data DATA]\n",
            "       [--hyp HYP]\n",
            "       [--epochs EPOCHS]\n",
            "       [--batch-size BATCH_SIZE]\n",
            "       [--imgsz IMGSZ]\n",
            "       [--rect]\n",
            "       [--resume [RESUME]]\n",
            "       [--nosave]\n",
            "       [--noval]\n",
            "       [--noautoanchor]\n",
            "       [--noplots]\n",
            "       [--evolve [EVOLVE]]\n",
            "       [--bucket BUCKET]\n",
            "       [--cache [CACHE]]\n",
            "       [--image-weights]\n",
            "       [--device DEVICE]\n",
            "       [--multi-scale]\n",
            "       [--single-cls]\n",
            "       [--optimizer {SGD,Adam,AdamW}]\n",
            "       [--sync-bn]\n",
            "       [--workers WORKERS]\n",
            "       [--project PROJECT]\n",
            "       [--name NAME]\n",
            "       [--exist-ok]\n",
            "       [--quad]\n",
            "       [--cos-lr]\n",
            "       [--label-smoothing LABEL_SMOOTHING]\n",
            "       [--patience PATIENCE]\n",
            "       [--freeze FREEZE [FREEZE ...]]\n",
            "       [--save-period SAVE_PERIOD]\n",
            "       [--seed SEED]\n",
            "       [--local_rank LOCAL_RANK]\n",
            "       [--entity ENTITY]\n",
            "       [--upload_dataset [UPLOAD_DATASET]]\n",
            "       [--bbox_interval BBOX_INTERVAL]\n",
            "       [--artifact_alias ARTIFACT_ALIAS]\n",
            "train.py: error: unrecognized arguments: --model yolov5s-cls.pt --pretrained weights/yolov5s-cls.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 766 --batch 2 --data custom_data.yaml --epochs 70 --weights yolov5x.pt --nosave --cache"
      ],
      "metadata": {
        "id": "Yu4CC5nziyAJ",
        "outputId": "829e213e-4a8d-4877-90b7-9af8b4a595d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=70, batch_size=2, imgsz=766, rect=False, resume=False, nosave=True, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "WARNING ‚ö†Ô∏è --img-size 766 must be multiple of max stride 32, updating to 768\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train_data/labels/train.cache... 10 images, 0 backgrounds, 0 corrupt: 100% 10/10 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 10/10 [00:00<00:00, 135.53it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train_data/labels/val.cache... 2 images, 0 backgrounds, 0 corrupt: 100% 2/2 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 2/2 [00:00<00:00, 21.53it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.77 anchors/target, 0.769 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ‚ö†Ô∏è Extremely small objects found: 2 of 26 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 26 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8311: 100% 1000/1000 [00:00<00:00, 3555.83it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9231 best possible recall, 5.85 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=768, metric_all=0.363/0.831-mean/best, past_thr=0.519-mean: 6,2, 327,73, 187,184, 651,62, 336,121, 667,106, 236,447, 584,181, 234,476\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "Image sizes 768 train, 768 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 70 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/69      3.68G     0.1045    0.05017          0          8        768: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  9.17it/s]\n",
            "                   all          2          5    0.00333        0.4    0.00487   0.000603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/69      3.68G     0.1081     0.0493          0          2        768: 100% 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 10.63it/s]\n",
            "                   all          2          5      0.005        0.6    0.00629    0.00108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/69      3.68G     0.1023    0.05222          0         11        768: 100% 5/5 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.26it/s]\n",
            "                   all          2          5      0.005        0.6    0.00589    0.00161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/69      3.68G     0.1052    0.05888          0         14        768: 100% 5/5 [00:01<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.80it/s]\n",
            "                   all          2          5    0.00833          1     0.0119    0.00171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/69      3.68G      0.102    0.06411          0         15        768: 100% 5/5 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.94it/s]\n",
            "                   all          2          5    0.00333        0.4    0.00551    0.00083\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/69      3.68G      0.103    0.05143          0          8        768: 100% 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.82it/s]\n",
            "                   all          2          5    0.00333        0.4    0.00551    0.00083\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/69      3.68G    0.09951    0.04919          0          3        768: 100% 5/5 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.59it/s]\n",
            "                   all          2          5    0.00333        0.4    0.00551    0.00083\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/69      3.68G    0.09875    0.06455          0         13        768: 100% 5/5 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.03it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0124    0.00155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/69      3.68G     0.1007    0.06068          0         13        768: 100% 5/5 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.11it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0124    0.00155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/69      3.68G     0.1004    0.06249          0         11        768: 100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.37it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0124    0.00155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/69      3.68G    0.09391    0.04976          0          3        768: 100% 5/5 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.18it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0139    0.00406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/69      3.68G    0.09758    0.05307          0          6        768: 100% 5/5 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.22it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0139    0.00406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/69      3.68G    0.09511    0.06061          0         11        768: 100% 5/5 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 10.55it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0139    0.00406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/69      3.68G    0.09752    0.05053          0         10        768: 100% 5/5 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.26it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0139    0.00406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/69      3.68G    0.09353    0.06292          0         12        768: 100% 5/5 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 10.80it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0139    0.00406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/69      3.68G    0.09421    0.05834          0          7        768: 100% 5/5 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.30it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/69      3.68G     0.0962    0.04787          0          8        768: 100% 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.19it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/69      3.68G    0.09502    0.06301          0         14        768: 100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 10.95it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/69      3.68G    0.08911    0.04986          0          6        768: 100% 5/5 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.30it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/69      3.68G    0.09527    0.07453          0         18        768: 100% 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.29it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/69      3.68G    0.09463    0.05695          0         16        768: 100% 5/5 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.45it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/69      3.68G    0.09391    0.05728          0         12        768: 100% 5/5 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.33it/s]\n",
            "                   all          2          5    0.00833          1     0.0248    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/69      3.68G    0.09435     0.0615          0         16        768: 100% 5/5 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.28it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/69      3.68G    0.09354    0.05431          0         11        768: 100% 5/5 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.31it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/69      3.68G    0.09141    0.06162          0         11        768: 100% 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 10.64it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/69      3.68G    0.09221    0.05884          0          7        768: 100% 5/5 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.09it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/69      3.68G     0.0906    0.05678          0          5        768: 100% 5/5 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.71it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/69      3.68G    0.09047    0.05315          0          8        768: 100% 5/5 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.10it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0181    0.00416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/69      3.68G    0.09141    0.06242          0         11        768: 100% 5/5 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.66it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/69      3.68G    0.09274    0.05284          0          3        768: 100% 5/5 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.78it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/69      3.68G    0.09036    0.06673          0         12        768: 100% 5/5 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.69it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/69      3.68G    0.08928    0.06062          0          3        768: 100% 5/5 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.13it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/69      3.68G    0.09216    0.05189          0          7        768: 100% 5/5 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.28it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/69      3.68G    0.09247    0.05366          0         10        768: 100% 5/5 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.84it/s]\n",
            "                   all          2          5    0.00833          1     0.0611     0.0163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/69      3.68G    0.08994    0.05677          0          9        768: 100% 5/5 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.41it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/69      3.68G    0.08586    0.06159          0         14        768: 100% 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.32it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/69      3.68G     0.0912    0.06503          0          7        768: 100% 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.01it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/69      3.68G    0.09104    0.04835          0          8        768: 100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.85it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/69      3.68G    0.09056    0.04818          0         10        768: 100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.87it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/69      3.68G    0.09661    0.05034          0          9        768: 100% 5/5 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.94it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/69      3.68G    0.09315    0.05564          0          6        768: 100% 5/5 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.51it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0192    0.00734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/69      3.68G    0.08865    0.07419          0          8        768: 100% 5/5 [00:01<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.35it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/69      3.68G    0.09165    0.05554          0         19        768: 100% 5/5 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.29it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/69      3.68G    0.09119    0.05101          0          6        768: 100% 5/5 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.27it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/69      3.68G    0.08968     0.0547          0         12        768: 100% 5/5 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.48it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/69      3.68G    0.09175    0.06066          0         15        768: 100% 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.28it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/69      3.68G    0.09551    0.04917          0         10        768: 100% 5/5 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.35it/s]\n",
            "                   all          2          5    0.00667        0.8       0.04     0.0179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/69      3.68G    0.08677     0.0595          0          4        768: 100% 5/5 [00:01<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.41it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/69      3.68G    0.08787    0.05831          0          3        768: 100% 5/5 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.37it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/69      3.68G    0.09174    0.05213          0         11        768: 100% 5/5 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.00it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/69      3.68G    0.08423    0.06019          0          7        768: 100% 5/5 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.48it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/69      3.68G    0.08126    0.07607          0         10        768: 100% 5/5 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.31it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/69      3.68G    0.08917    0.05285          0         10        768: 100% 5/5 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.80it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/69      3.68G    0.08866     0.0537          0         10        768: 100% 5/5 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.96it/s]\n",
            "                   all          2          5    0.00667        0.8      0.034     0.0135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/69      3.68G    0.08979    0.06541          0         12        768: 100% 5/5 [00:01<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.57it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/69      3.68G    0.06879    0.05667          0         11        768: 100% 5/5 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.50it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/69      3.68G    0.09433    0.06158          0         22        768: 100% 5/5 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.03it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/69      3.68G    0.09089    0.04737          0          6        768: 100% 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.08it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/69      3.68G    0.09764    0.04868          0         15        768: 100% 5/5 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.66it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/69      3.68G     0.0895    0.04926          0          7        768: 100% 5/5 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.62it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0322     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/69      3.68G    0.08482    0.05075          0         10        768: 100% 5/5 [00:01<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.38it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/69      3.68G    0.07924      0.068          0          5        768: 100% 5/5 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 11.87it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/69      3.68G    0.08705    0.05603          0         15        768: 100% 5/5 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.60it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/69      3.68G    0.08559    0.05579          0          9        768: 100% 5/5 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.66it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/69      3.68G    0.09023    0.05225          0          8        768: 100% 5/5 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.63it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/69      3.68G    0.08653    0.05013          0          7        768: 100% 5/5 [00:01<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.55it/s]\n",
            "                   all          2          5    0.00833          1      0.028    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/69      3.68G    0.08421    0.05563          0         10        768: 100% 5/5 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 13.11it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0275    0.00517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/69      3.68G     0.0828    0.06083          0          9        768: 100% 5/5 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.85it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0275    0.00517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/69      3.68G    0.09075    0.04902          0          6        768: 100% 5/5 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.21it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0275    0.00517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/69      3.68G    0.08521    0.06313          0          9        768: 100% 5/5 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00, 12.06it/s]\n",
            "                   all          2          5    0.00667        0.8     0.0275    0.00517\n",
            "\n",
            "70 epochs completed in 0.026 hours.\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 173.1MB\n",
            "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate Your Custom Model\n",
        "\n",
        "Repeat step 2 from above to test and validate your custom model."
      ],
      "metadata": {
        "id": "HHUFGeLbGd98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data ../datasets/$DATASET_NAME"
      ],
      "metadata": {
        "id": "DIV7ydyKGZFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer With Your Custom Model"
      ],
      "metadata": {
        "id": "uH5tJNpEsi6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the path of an image from the test or validation set\n",
        "if os.path.exists(os.path.join(dataset.location, \"test\")):\n",
        "  split_path = os.path.join(dataset.location, \"test\")\n",
        "else:\n",
        "  os.path.join(dataset.location, \"valid\")\n",
        "example_class = os.listdir(split_path)[0]\n",
        "example_image_name = os.listdir(os.path.join(split_path, example_class))[0]\n",
        "example_image_path = os.path.join(split_path, example_class, example_image_name)\n",
        "os.environ[\"TEST_IMAGE_PATH\"] = example_image_path\n",
        "\n",
        "print(f\"Inferring on an example of the class '{example_class}'\")\n",
        "\n",
        "#Infer\n",
        "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source $TEST_IMAGE_PATH"
      ],
      "metadata": {
        "id": "81lK1hU_sk54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the inference results show ~3ms inference and the respective classes predicted probabilities."
      ],
      "metadata": {
        "id": "DdGuG-1kNjWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (OPTIONAL) Improve Our Model with Active Learning\n",
        "\n",
        "Now that we've trained our model once, we will want to continue to improve its performance. Improvement is largely dependent on improving our dataset.\n",
        "\n",
        "We can programmatically upload example failure images back to our custom dataset based on conditions (like seeing an underrpresented class or a low confidence score) using the same `pip` package."
      ],
      "metadata": {
        "id": "I38IM6NXKNN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload example image\n",
        "# project.upload(image_path)\n"
      ],
      "metadata": {
        "id": "HycgSEnYKo0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example upload code \n",
        "# min_conf = float(\"inf\")\n",
        "# for pred in results:\n",
        "#     if pred[\"score\"] < min_conf:\n",
        "#         min_conf = pred[\"score\"]\n",
        "# if min_conf < 0.4:\n",
        "#     project.upload(image_path)"
      ],
      "metadata": {
        "id": "VwXDoz_vLK3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (BONUS) YOLOv5 classify/predict.py Accepts Several Input Methods\n",
        "- Webcam: `python classify/predict.py --weights yolov5s-cls.pt --source 0`\n",
        "- Image `python classify/predict.py --weights yolov5s-cls.pt --source img.jpg`\n",
        "- Video: `python classify/predict.py --weights yolov5s-cls.pt --source vid.mp4`\n",
        "- Directory: `python classify/predict.py --weights yolov5s-cls.pt --source path/`\n",
        "- Glob: `python classify/predict.py --weights yolov5s-cls.pt --source 'path/*.jpg'`\n",
        "- YouTube: `python classify/predict.py --weights yolov5s-cls.pt --source 'https://youtu.be/Zgi9g1ksQHc'`\n",
        "- RTSP, RTMP, HTTP stream: `python classify/predict.py --weights yolov5s-cls.pt --source 'rtsp://example.com/media.mp4'`"
      ],
      "metadata": {
        "id": "aYlfaHDusN-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Directory Example"
      ],
      "metadata": {
        "id": "iKSP-SNTvcLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Directory infer\n",
        "os.environ[\"TEST_CLASS_PATH\"] = test_class_path = os.path.join(*os.environ[\"TEST_IMAGE_PATH\"].split(os.sep)[:-1])\n",
        "print(f\"Infering on all images from the directory {os.environ['TEST_CLASS_PATH']}\")\n",
        "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source /$TEST_CLASS_PATH/"
      ],
      "metadata": {
        "id": "lwSoHcHcvjeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###YouTube Example"
      ],
      "metadata": {
        "id": "kCCao9t8se8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YouTube infer\n",
        "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source 'https://www.youtube.com/watch?v=7AlYA4ItA74'"
      ],
      "metadata": {
        "id": "heebjpJBsakV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}